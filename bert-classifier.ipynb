{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1638,"sourceType":"datasetVersion","datasetId":897},{"sourceId":7389273,"sourceType":"datasetVersion","datasetId":4295346}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:25:44.801204Z","iopub.execute_input":"2024-12-01T21:25:44.801912Z","iopub.status.idle":"2024-12-01T21:25:52.788209Z","shell.execute_reply.started":"2024-12-01T21:25:44.801869Z","shell.execute_reply":"2024-12-01T21:25:52.787036Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade jupyterlab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:25:52.790675Z","iopub.execute_input":"2024-12-01T21:25:52.791395Z","iopub.status.idle":"2024-12-01T21:26:01.397898Z","shell.execute_reply.started":"2024-12-01T21:25:52.791355Z","shell.execute_reply":"2024-12-01T21:26:01.396940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install --upgrade ipywidgets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:01.399219Z","iopub.execute_input":"2024-12-01T21:26:01.399523Z","iopub.status.idle":"2024-12-01T21:26:09.457676Z","shell.execute_reply.started":"2024-12-01T21:26:01.399490Z","shell.execute_reply":"2024-12-01T21:26:09.456577Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport kagglehub\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import CosineAnnealingLR","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:09.460451Z","iopub.execute_input":"2024-12-01T21:26:09.460852Z","iopub.status.idle":"2024-12-01T21:26:09.466988Z","shell.execute_reply.started":"2024-12-01T21:26:09.460808Z","shell.execute_reply":"2024-12-01T21:26:09.465956Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndf = pd.read_csv(kagglehub.dataset_download('samdeeplearning/deepnlp').join(['', '/Sheet_2.csv']), encoding='latin_1')\n\ndf['label'] = df['class'].map({'flagged': 1, 'not_flagged': 0})\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:09.468139Z","iopub.execute_input":"2024-12-01T21:26:09.468570Z","iopub.status.idle":"2024-12-01T21:26:10.379897Z","shell.execute_reply.started":"2024-12-01T21:26:09.468533Z","shell.execute_reply":"2024-12-01T21:26:10.379225Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.380957Z","iopub.execute_input":"2024-12-01T21:26:10.381353Z","iopub.status.idle":"2024-12-01T21:26:10.702699Z","shell.execute_reply.started":"2024-12-01T21:26:10.381311Z","shell.execute_reply":"2024-12-01T21:26:10.701779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResumeDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.iloc[idx]['resume_text']\n        label = self.df.iloc[idx]['label']\n        encoding = self.tokenizer.encode_plus(\n            text,\n            truncation=True,\n            max_length=self.max_length,\n            padding='max_length',\n            return_tensors='pt',\n        )\n        input_ids = encoding['input_ids'].squeeze()\n        attention_mask = encoding['attention_mask'].squeeze()\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.703764Z","iopub.execute_input":"2024-12-01T21:26:10.704022Z","iopub.status.idle":"2024-12-01T21:26:10.710363Z","shell.execute_reply.started":"2024-12-01T21:26:10.703996Z","shell.execute_reply":"2024-12-01T21:26:10.709243Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = ResumeDataset(train_df, tokenizer)\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\nval_dataset = ResumeDataset(val_df, tokenizer)\nval_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.711520Z","iopub.execute_input":"2024-12-01T21:26:10.711786Z","iopub.status.idle":"2024-12-01T21:26:10.726284Z","shell.execute_reply.started":"2024-12-01T21:26:10.711761Z","shell.execute_reply":"2024-12-01T21:26:10.725601Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_samples = len(train_df)\nnum_class_0 = len(train_df[train_df['label'] == 0])\nnum_class_1 = len(train_df[train_df['label'] == 1])\nweight_class_0 = num_samples / (2.0 * num_class_0)\nweight_class_1 = num_samples / (2.0 * num_class_1)\nclass_weights = torch.tensor([weight_class_0, weight_class_1], dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\nloss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.727153Z","iopub.execute_input":"2024-12-01T21:26:10.727413Z","iopub.status.idle":"2024-12-01T21:26:10.737312Z","shell.execute_reply.started":"2024-12-01T21:26:10.727389Z","shell.execute_reply":"2024-12-01T21:26:10.736652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training set class distribution:\")\nprint(train_df['label'].value_counts())\nprint(\"\\nValidation set class distribution:\")\nprint(val_df['label'].value_counts())\nprint(f'first class weights\\' scale = {weight_class_0}, second = {weight_class_1}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.740307Z","iopub.execute_input":"2024-12-01T21:26:10.740929Z","iopub.status.idle":"2024-12-01T21:26:10.751108Z","shell.execute_reply.started":"2024-12-01T21:26:10.740902Z","shell.execute_reply":"2024-12-01T21:26:10.750244Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:26:10.752128Z","iopub.execute_input":"2024-12-01T21:26:10.752407Z","iopub.status.idle":"2024-12-01T21:26:11.001455Z","shell.execute_reply.started":"2024-12-01T21:26:10.752383Z","shell.execute_reply":"2024-12-01T21:26:11.000673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5)\nscheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * 2)\n\n# Define loss function with class weights\nclass_weights = torch.tensor([weight_class_0, weight_class_1], dtype=torch.float).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\nloss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n\n# Training loop\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nfor epoch in range(50):\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for batch in train_loader:\n        optimizer.zero_grad()\n        \n        inputs = {\n            'input_ids': batch['input_ids'].to(device),\n            'attention_mask': batch['attention_mask'].to(device),\n            'labels': batch['labels'].to(device)\n        }\n        \n        outputs = model(**inputs)\n        loss = loss_fn(outputs.logits, inputs['labels'])\n        \n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.logits, 1)\n        correct += (predicted == inputs['labels']).sum().item()\n        total += inputs['labels'].size(0)\n    \n    scheduler.step()\n    \n    # Calculate and print training loss and accuracy\n    train_loss /= len(train_loader)\n    train_accuracy = correct / total\n    print(f'Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}, Learning Rate: {scheduler.get_lr()}')\n    \n    # Validation loop\n    model.eval()\n    correct_val = 0\n    total_val = 0\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            inputs = {\n                'input_ids': batch['input_ids'].to(device),\n                'attention_mask': batch['attention_mask'].to(device),\n                'labels': batch['labels'].to(device)\n            }\n            \n            outputs = model(**inputs)\n            predictions = torch.argmax(outputs.logits, dim=1)\n            correct_val += (predictions == inputs['labels']).sum().item()\n            total_val += inputs['labels'].size(0)\n    \n    # Calculate and print validation accuracy\n    val_accuracy = correct_val / total_val\n    print(f'Epoch {epoch+1}, Validation Accuracy: {val_accuracy:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T21:47:00.854957Z","iopub.execute_input":"2024-12-01T21:47:00.855316Z","iopub.status.idle":"2024-12-01T21:51:18.185749Z","shell.execute_reply.started":"2024-12-01T21:47:00.855283Z","shell.execute_reply":"2024-12-01T21:51:18.184654Z"}},"outputs":[],"execution_count":null}]}